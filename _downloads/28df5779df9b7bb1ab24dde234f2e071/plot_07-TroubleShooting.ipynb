{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n07: Tuning & Troubleshooting\n============================\n\nTips & tricks for choosing algorithm settings, tuning fits, and troubleshooting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# General imports\nimport numpy as np\n\n# Import the FOOOF and FOOOFGroup objects\nfrom fooof import FOOOF, FOOOFGroup\n\n# Import some utilities for creating simulated power-spectra\nfrom fooof.sim.params import param_sampler\nfrom fooof.sim.gen import gen_power_spectrum, gen_group_power_spectra\nfrom fooof.sim.utils import set_random_seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algorithm Settings\n------------------\n\nWith default settings, the power spectrum model is relatively minimally constrained. It\ndefaults as such since there are not universal settings that work across all different\nrecording modalities. Appropriate settings also vary with power spectrum quality (noise,\nor effectively, the smoothness of the power spectrum), and frequency ranges.\n\nFor any given dataset, you will likely have to tune some of the algorithm settings\nfor optimal performance.\n\nTo do so, we suggest using a combination of the following considerations:\n\n- A priori constraints, given your data, such as the number of peaks you expect to extract\n- Qualitative analysis, guided by examining the the plotted model fit results,\n  as compared to input data\n- Quantitative analysis, considering the model goodness of fit metrics\n  (however, see note at the bottom regarding interpreting these metrics)\n\nChoosing settings to tune model fitting is an imperfect art, and should be done carefully,\nas assumptions built into the settings chosen will impact the model results. Model\nfitting is generally not overly sensitive to small changes in the settings, so as long\nas broadly appropriate settings are chosen, small perturbations to these chosen settings\nshould not have a large impact on the fitting.\n\nWe do recommend that model settings should not be changed between power spectra\n(across channels, trials, or subjects), if they are to be meaningfully compared.\nWe therefore recommend first testing fitting the model across some representative\nspectra, in order to select settings, which you then keep constant for the full analysis.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tuning the Algorithm\n--------------------\n\nWith default settings, the model fit is fairly liberal at fitting peaks, and so\nmost commonly this will lead to overfitting, being overzealous at fitting small\nnoisy bumps as peaks.\n\nIn some cases, you may also find you need to relax some settings, to get better fits.\n\nYou also need to make sure you pick an appropriate aperiodic fitting procedure,\nand that your data meets the assumptions of the approach you choose (see the tutorial\non aperiodic fitting).\n\nThe remainder of this notebook goes through some examples of choosing settings\nfor different datasets.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpreting Model Fit Quality Measures\n---------------------------------------\n\nAfter model fitting, some goodness of fit metrics are calculated to assist with assessing\nthe quality of the model fits. It calculates both the model fit error, as the mean absolute\nerror (MAE) between the full model fit (``fooofed_spectrum_``) and the original power spectrum,\nas well as the R-squared correspondence between the original spectrum and the full model.\n\nThese scores can be used to assess how the model is performing. However interpreting these\nmeasures requires a bit of nuance. Model fitting is NOT optimized to minimize fit error /\nmaximize r-squared at all costs. To do so typically results in fitting a large number of peaks,\nin a way that overfits noise, and only artificially reduces error / maximizes r-squared.\n\nThe power spectrum model is therefore tuned to try and measure the aperiodic component\nand peaks in a parsimonious manner, and, fit the `right` model (meaning the right aperiodic\ncomponent and the right number of peaks) rather than the model with the lowest error.\n\nGiven this, while high error / low r-squared may indicate a poor model fit, very low\nerror / high r-squared may also indicate a power spectrum that is overfit, in particular\nin which the peak parameters from the model may reflect overfitting by fitting too many peaks.\n\nWe therefore recommend that, for a given dataset, initial explorations should involve\nchecking both cases in which model fit error is particularly large, as well as when it\nis particularly low. These explorations can be used to pick settings that are suitable\nfor running across a group. There are not universal settings that optimize this, and so\nit is left up to the user to choose settings appropriately to not under- or over-fit\nfor a given modality / dataset / application.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reducing Overfitting\n--------------------\n\nIf the model appears to be overfitting (for example, fitting too many peaks to small bumps), try:\n\n- Setting a lower-bound bandwidth-limit, to exclude fitting very narrow peaks, that may be noise\n- Setting a maximum number of peaks that the algorithm may fit: `max_n_peaks`\n\n  - If set, the algorithm will fit (up to) the `max_n_peaks` highest power peaks.\n- Setting a minimum absolute peak height: `min_peak_height`\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulating Power Spectra\n------------------------\n\nFor this example, we will use simulated data. The FOOOF module includes utilities\nfor creating simulated power-spectra. To do so, we can use the :func:`~.gen_power_spectrum`\nfunction to simulate individual power spectra, following the power spectrum model.\n\nFirst, we will start by generating a noisy simulated power spectrum\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set the frequency range to generate the power spectrum\nf_range = [1, 50]\n# Set aperiodic component parameters, as [offset, exponent]\nap_params = [20, 2]\n# Gaussian peak parameters\ngauss_params = [[10, 1.0, 2.5], [20, 0.8, 2], [32, 0.6, 1]]\n# Set the level of noise to generate the power spectrum with\nnlv = 0.1\n\n# Set random seed, for consistency generating simulated data\nset_random_seed(21)\n\n# Create a simulated power spectrum\nfreqs, spectrum = gen_power_spectrum(f_range, ap_params, gauss_params, nlv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fit an (unconstrained) model, liable to overfit\nfm = FOOOF()\nfm.report(freqs, spectrum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that in the above fit, we are very likely to think that the model has\nbeen overzealous in fitting peaks, and is therefore overfitting.\n\nThis is also suggested by the model r-squared, which is suspiciously\nhigh, given the amount of noise we in the simulated power spectrum.\n\nTo reduce this kind of overfitting, we can update the algorithm settings.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Update settings to fit a more constrained model, to reduce overfitting\nfm = FOOOF(peak_width_limits=[1, 8], max_n_peaks=6, min_peak_height=0.4)\nfm.report(freqs, spectrum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare how the model fit, using the updated settings, compares to the\nground truth of the simulated spectrum.\n\nNote that the simulation parameters are defined in terms of Gaussian parameters,\nwhich are slightly different from the peak parameters (see the note in tutorial 02),\nwhich is why we compare to the model gaussian parameters here.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compare ground truth simulated parameters to model fit results\nprint('Ground Truth \\t\\t Model Parameters')\nfor sy, fi in zip(np.array(gauss_params), fm.gaussian_params_):\n    print('{:5.2f} {:5.2f} {:5.2f} \\t {:5.2f} {:5.2f} {:5.2f}'.format(*sy, *fi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Power Spectra with No Peaks\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nA known case in which the model can overfit is in power spectra in which no peaks are\npresent. In this case, the standard deviation can be very low, and so the relative\npeak height check (``min_peak_threshold``) is very liberal at keeping gaussian fits.\n\nIf you expect, or know, you have power spectra without peaks in your data,\nwe recommend using the ``min_peak_height`` setting. Otherwise, the model is unlikely to\nappropriately fit power spectra as having no peaks, since it uses only a relative\nthreshold if ``min_peak_height`` is set to zero (which is the default value).\nSetting ``min_peak_height`` requires checking the scale of your power spectra,\nallowing you to define an absolute threshold for extracting peaks.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reducing Underfitting\n---------------------\n\nIf you are finding that the model is underfitting:\n\n- First check and perhaps loosen any restrictions from ``max_n_peaks`` and ``min_peak_height``\n- Try updating ``peak_threshold`` to a lower value\n- Bad fits may stem from issues with aperiodic component fitting\n\n  - Double check that you are using the appropriate aperiodic mode\n\nNext we will simulate a much smoother power spectrum, and update settings accordingly.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set the frequency range to generate the power spectrum\nf_range = [1, 50]\n# Define aperiodic parameters, as [offset, exponent]\nap_params = [20, 2]\n# Define peak parameters, each peak defined as [CF, PW, BW]\ngauss_params = [[10, 1.0, 1.0], [20, 0.3, 1.5], [32, 0.25, 1]]\n# Set the level of noise to generate the power spectrum with\nnlv = 0.025\n\n# Create a simulated power spectrum\nfreqs, spectrum = gen_power_spectrum([1, 50], ap_params, gauss_params, nlv=nlv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Update settings to make sure they are sensitive to smaller peaks in smoother power spectra\nfm = FOOOF(peak_width_limits=[1, 8], max_n_peaks=6, min_peak_height=0.2)\nfm.report(freqs, spectrum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check reconstructed parameters compared to the simulated parameters\nprint('Ground Truth \\t\\t Model Parameters')\nfor sy, fi in zip(np.array(gauss_params), fm.gaussian_params_):\n    print('{:5.2f} {:5.2f} {:5.2f} \\t {:5.2f} {:5.2f} {:5.2f}'.format(*sy, *fi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking Fits Across a Group\n----------------------------\n\nSo far we have explored troubleshooting individual model fits. When starting\na new analysis, or working with a new dataset, we do recommend starting by\ntrying some individual fits like this.\n\nIf and when you move to using :class:`~fooof.FOOOFGroup` to fit groups of power spectra,\nthere are some slightly different ways to investigate groups of fits,\nwhich we'll step through now, using some simulated data.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulating a Group of Power Spectra\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nWe will continue using simulated data, this time simulating a group of power spectra.\n\nTo simulate a group of power spectra, we will use the :func:`~.gen_group_power_spectra`\nin combination with called :func:`~.param_sampler` that is used to sample across\npossible parameters.\n\nFor more and descriptions and example of how the simulations work, check out the\n`examples <https://fooof-tools.github.io/fooof/auto_examples/index.html>`_ section.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Simulation settings for a group of power spectra\nn_spectra = 10\nsim_freq_range = [3, 50]\nnlv = 0.010\n\n# Set the parameter options for aperiodic component and peaks\nap_opts = param_sampler([[20, 2], [50, 2.5], [35, 1.5]])\ngauss_opts = param_sampler([[], [10, 0.5, 2], [10, 0.5, 2, 20, 0.3, 4]])\n\n# Simulate a group of power spectra\nfreqs, power_spectra = gen_group_power_spectra(n_spectra, sim_freq_range,\n                                               ap_opts, gauss_opts, nlv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize a FOOOFGroup object\nfg = FOOOFGroup(peak_width_limits=[1, 6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fit power spectrum models and report on the group\nfg.report(freqs, power_spectra)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the :class:`~fooof.FOOOFGroup` report we can get a sense of the overall performance\nby looking at the information about the goodness of fit metrics, and also things like\nthe distribution of peaks.\n\nHowever, while these metrics can help identify if fits are, on average, going well (or not)\nthey don't necessarily indicate the source of any problems.\n\nTo do so, we will typically still want to visualize some example fits, to see\nwhat is happening. To do so, next we will find which fits have the most error,\nand select these fits from the :class:`~fooof.FOOOFGroup` object to visualize.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Find the index of the worst model fit from the group\nworst_fit_ind = np.argmax(fg.get_params('error'))\n\n# Extract this model fit from the group\nfm = fg.get_fooof(worst_fit_ind, regenerate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check results and visualize the extracted model\nfm.print_results()\nfm.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also loop through all the results in a :class:`~fooof.FOOOFGroup`, extracting\nall fits that meet some criterion that makes them worth checking.\n\nThis might be checking for fits above some error threshold, as below, but note\nthat you may also want to do a similar procedure to examine fits with the lowest\nerror, to check if the model may be overfitting, or perhaps fits with a particularly\nlarge number of gaussians.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Extract all fits that are above some error threshold, for further examination.\n#  You could also do a similar analysis for particularly low errors\nerror_threshold = 0.010\nto_check = []\nfor ind, res in enumerate(fg):\n    if res.error > error_threshold:\n        to_check.append(fg.get_fooof(ind, regenerate=True))\n\n# A more condensed version of the procedure above can be written like this:\n#to_check = [fg.get_fooof(ind, True) for ind, res in enumerate(fg) if res.error > error_threshold]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Loop through the problem fits, checking the plots, and saving out reports, to check later.\nfor ind, fm in enumerate(to_check):\n    fm.plot()\n    fm.save_report('Report_ToCheck_#' + str(ind))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another thing that can be worth keeping an eye on is the average number of fit\npeaks per model. A particularly high value can indicate overfitting.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check the average number of fit peaks, per model\nprint('Average number of fit peaks: ', np.mean(fg.n_peaks_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reporting Bad Fits\n------------------\n\nIf, after working through these suggestions, you are still getting bad fits, and/or\nare just not sure what is going on, please get in touch! We will hopefully be able to\nmake further recommendations, and this also serves as a way for us to investigate when\nand why model fitting fails, so that we can continue to make it better.\n\nYou can report issues on Github `here <https://github.com/fooof-tools/fooof>`.\n\nThere is also a helper method to print out instructions for reporting\nbad fits / bugs back to us, as demonstrated below.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Print out instructions to report bad fits\n#  Note you can also call this from FOOOFGroup, and from instances (ex: `fm.print_report_issue()`)\nFOOOF.print_report_issue()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion\n----------\n\nWe have now stepped through the full work-flow of fitting power spectrum models, using\nFOOOF objects, picking settings, and troubleshooting model fits. In the next\nand final tutorial, we will introduce how to start analyzing FOOOF results.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}